<html>
<body>
        <style>
        * {
          box-sizing: border-box;
        }
        .btn {
  font-family: "Jost", sans-serif;
  font-weight: 500;
  font-size: 16px;
  letter-spacing: 1px;
  display: inline-block;
  padding: 12px 40px;
  border-radius: 50px;
  transition: 0.5s;
  margin: 10px;
  border: 2px solid #47b2e4;
  color: #47b2e4;
}

.btn:hover {
  background: #47b2e4;
  border: 2px solid #47b2e4;
  color: white;
}
#label-container{
font-size: 20;
font-family:'Times New Roman', Times, serif;
}
</style><center>
<button type="button" onclick="init()" class="btn">Start</button><br><br>
<div id="webcam-container"></div><br><br>
<div id="label-container"></div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
  <script type="text/javascript">
      // More API functions here:
      // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
  
      // the link to your model provided by Teachable Machine export panel
      const URL = "https://teachablemachine.withgoogle.com/models/HzN6fXkq9/";

let model, webcam, labelContainer, maxPredictions;

// Load the image model and setup the webcam
async function init() {
  const modelURL = URL + "model.json";
  const metadataURL = URL + "metadata.json";

  // Load the model and metadata
  model = await tmImage.load(modelURL, metadataURL);
  maxPredictions = model.getTotalClasses();

  // Convenience function to setup a webcam
  const flip = true; // Whether to flip the webcam
  webcam = new tmImage.Webcam(300, 300, flip); // Width, height, flip

  // Check if environment camera is available
  if (navigator.mediaDevices && navigator.mediaDevices.enumerateDevices) {
    const devices = await navigator.mediaDevices.enumerateDevices();
    const environmentCameras = devices.filter(device => device.kind === 'videoinput');
    
    if (environmentCameras.length > 1) {
      // Use environment camera if available
      const environmentCamera = environmentCameras[1];
      const constraints = {
        video: {
          deviceId: environmentCamera.deviceId,
          facingMode: { exact: "environment" }
        }
      };
      await webcam.setup(constraints);
    }
  }



  await webcam.play();
  window.requestAnimationFrame(loop);

  // Append elements to the DOM
  document.getElementById("webcam-container").appendChild(webcam.canvas);
  labelContainer = document.getElementById("label-container");
  for (let i = 0; i < maxPredictions; i++) { // and class labels
    labelContainer.appendChild(document.createElement("div"));
  }
}

async function loop() {
  webcam.update(); // Update the webcam frame
  await predict();
  window.requestAnimationFrame(loop);
}

// Run the webcam image through the image model
async function predict() {
  // Predict can take in an image, video, or canvas HTML element
  const prediction = await model.predict(webcam.canvas);
  for (let i = 0; i < maxPredictions; i++) {
    const classPrediction =
      prediction[i].className + ": " + (prediction[i].probability.toFixed(2) * 100);
    labelContainer.childNodes[i].innerHTML = classPrediction + "%";
  }
}

// Call the init function to start the application
init();
</script></div></center>
</body>
</html>
